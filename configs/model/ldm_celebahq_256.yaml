_target_: src.models.dlir_ni_module.EvalModule

# guidence_module:
#   _partial_: true
#   _target_: src.models.components.guidence_modules.LatentDeepLatentIterativeReconstruct
#   scale: 0.01
#   optimizer:
#     _target_: src.models.components.guidence_modules.AdamOptimizer
#   # degrade_op: 
#   #   _target_: src.models.components.measurement_ops.SuperResolutionOp
#   #   scale_factor: 4
#   # degrade_op: 
#   #   _target_: src.models.components.measurement_ops.ColorizationOp
#   degrade_op: ${degrade_op}
#     # _target_: src.models.components.measurement_ops.CenterBoxInpaintingOP
#     # im_size: 256
#     # box_size: 128
#   # degrade_op:
#   #   _target_: src.models.components.measurement_ops.MotionBlurOp
#   #   kernel_size: 61
#   #   intensity: 0.5
#   #   device: "cuda"
#   # degrade_op:
#   #   _target_: src.models.components.measurement_ops.MotionBlurOp
#   #   kernel_size: 61
#   #   intensity: 0.5
#   #   device: "cuda"
#   # degrade_op:
#   #   _target_: src.models.components.measurement_ops.CTSparseViewOp
#   #   num_views: 64
#   #   det_shape: [512,]
#   #   im_shape: [256, 256]
#   #   angles: 3.1415926536 # 180 degrees
#     # angles: 1.5707963268 # 90 degrees
#     # angles: 0.7853981634 # 45 degrees
#   diff_module:
#     _target_: src.models.components.guidence_modules.NormModule
#     ord: 1
#     # _target_: torchmetrics.image.lpip.LearnedPerceptualImagePatchSimilarity
#   noise_op: ${noise_op}
    
guidence_module: ${guidence}

pipeline:
  _target_: src.models.components.pipelines.LatentReconstructionPipeline
  _partial_: true
  scheduler:
    _target_: diffusers.DDPMScheduler
    num_train_timesteps: 1000
    beta_schedule: "linear"
    prediction_type: "epsilon"
    clip_sample: True
    clip_sample_range: 1.0
  latents_height: 64
  latents_width: 64

unet:
  _target_: diffusers.UNet2DModel
  sample_size: 64
  in_channels: 3
  out_channels: 3
  layers_per_block: 2
  block_out_channels: [224, 448, 672, 896]
  center_input_sample: False
  downsample_padding: 1
  flip_sin_to_cos: True
  freq_shift: 0
  mid_block_scale_factor: 1
  norm_eps: 1e-5
  norm_num_groups: 32
  attention_head_dim: 32
  act_fn: "silu"
  time_embedding_type: "positional"
  down_block_types: ["DownBlock2D", "AttnDownBlock2D", "AttnDownBlock2D", "AttnDownBlock2D"]
  up_block_types: ["AttnUpBlock2D", "AttnUpBlock2D", "AttnUpBlock2D", "UpBlock2D"]

vqvae:
  _target_: diffusers.models.VQModel
  in_channels: 3
  out_channels: 3
  layers_per_block: 2
  down_block_types: ["DownEncoderBlock2D", "DownEncoderBlock2D", "DownEncoderBlock2D"]
  up_block_types: ["UpDecoderBlock2D", "UpDecoderBlock2D", "UpDecoderBlock2D"]
  block_out_channels: [128, 256, 512]
  latent_channels: 3
  num_vq_embeddings: 8192
  sample_size: 256
  act_fn: "silu"

unet_ckpt_path: ${paths.data_dir}ckpt/ldm_celebahq_256/unet.bin
vqvae_ckpt_path: ${paths.data_dir}ckpt/ldm_celebahq_256/vqvae.bin

im_out_dir: ${paths.eval_dir}/ni_sr_test